{
  
    
        "post0": {
            "title": "Live Coding Session 3",
            "content": "Relevant Material . Live Coding Session 3 Forum . . Note: These are my personal notes. They are not meant to be a comprehensive summary, but rather the things I wanted to note down for myself to refer to at a later point. . At the end of this lesson you will have: . ... | . Notes . Why not use virtual environment? . Virtual environments are separate folders with separate installations of Python and Python libraries. Good for keeping different projects separated with different sets of dependencies/versions. Jeremy prefers to have all his projects be compatible with each other and therefore has a baseline environment which he uses for all his projects. | He manages this by: Using a single base environment | Keeping libraries up to date | Having good tests that can tell if some new release has broken something | . | Exception: when Jeremy wants to check if something works with a specific version of Python. | How to uninstall mamba: rm -rf mamba forge | . PATH and virtual environment . Terminals use something called PATH, which is a list of places from which to run programs. | View PATH variable: echo $PATH | mamba directory looks very similar to Linux root directory | .bashrc sets PATH variable | Create a new environment called tmp: mamba create -n tmp &#39;python&lt;3.10&#39; fastcore | Activate new environment: mamba activate tmp | Deactivate: mamba deactivate | . Paperspace . Most of the time you won&#39;t (or shouldn&#39;t) be using a GPU. However when you do, it should feel as much as possible as if you are using your own computer and shouldn&#39;t cost you much (if any) money &rarr; Paperspace | With Gradient Notebooks you can get a free GPU server which behaves a lot like what we have worked with so far | . Debugging in Jupyter . Start debugger: %% debug | Starts a REPL, some useful commands: h=help, s=step into, n=next, c=continue, l=list, q=quit | Note: breakpoint() does not work in Jupyter due to some unresolved bug | You can use pdb to step into library code as well | . How to ensure libraries we install are not deleted when Paperspace is restarted . Since Paperspace does not offer a real server, whatever you install, will not be there the next time you start it up | Paperspace does have persistent storage however. There is a folder called storage in the root directory. Whatever you store in there, will be there next time you start up the Paperspace &#39;server&#39;. View all drives and how much space is available: df -h | . | In contrast to conda/mamba, pip allows for us to install libraries in our home directory (cd ~) rather than in the root directory (cd /). We would want to do this if we do not have access to the root directory or we cannot save in the root directory. This is done by: pip install --user [library] For data science libraries, usually it is better to use conda/mamba. For example if you want to install PyTorch it is better to use conda/mamba, as it takes care of the dependencies for you. If you pip install it on the other hand, you will need to install CUDA SDK separately for instance. | However, pip is fine for installing libraries without those types of dependencies. For most regular Python libraries, pip is fine. | . | When installing via pip with the --user flag, a new folder called .local is created in the home directory and the package will be installed in there. | We want the .local directory to persist across sessions: We move it to root/storage: mv .local /storage | But Python needs it in the home directory. For this we create a &#39;symbolic link&#39; aka &#39;symlink&#39; (basically a shortcut): ln -s /storage/.local | .local will now persist across sessions, however symlink will be removed. Paperspace runs a file every time on startup called pre-run.sh. We can use this file to create the symlink every time a notebook is started. | | . git folder on Paperspace . Jeremy has a git folder in /notebooks (sym linked, source directory is inside /storage). This is used to git clone repositories into it. (Needs to end up in pre-run.sh) | . SSH key on paperspace . There are 2 options: Use pre-existing SSH key (same as my local machine) Jeremy&#39;s preference, because he doesn&#39;t want to do too much &#39;SSH key admin&#39; | How to: Generate ssh key with ssh-keygen | Move to /storage: mv .ssh /storage | Sym link (needs to end up in pre-run.sh): ln -s /storage/.ssh | Edit contents of id_rsa and is_rsa.pub (not sure if latter is needed). | Check if permissions match that of default ssh key. If not: chmod ag-rw id_rsa | chmod ag-w id_rsa.pub | . | . | . | Generate new one for Paperspace | | Check by ssh into github: ssh git@github.com &rarr; Returned text should mention your github username | . | .",
            "url": "https://kemal-nl.github.io/personal-blog/live-coding/2022/08/13/fastai-livecoding-3.html",
            "relUrl": "/live-coding/2022/08/13/fastai-livecoding-3.html",
            "date": " • Aug 13, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Book Chapter 1",
            "content": "Relevant Material . fast.ai Book Chapter 1 (Jupyter Notebook) . fast.ai Book . . Note: These are my personal notes. They are not meant to be a comprehensive summary, but rather the things I wanted to note down for myself to refer to at a later point. . Notes . Deep Learning is for Everyone . It is a commonly held belief that in order for you to do deep learning successfully, you need: anything beyond high school math | inordinate amounts of data that ordinary individuals do not have access too | prohibitively expensive hardware | . | What is deep learning essentially? Technique to extract and transform data | By making use of multiple layers of neural networks. Each of these layers takes inputs from previous layers and progressively refines them. | Layers are trained by algorithms that minimizes their errors and improves accuracy. | . | Due to Deep Learning&#39;s versatility and power, its application space is vast and often it is the dominant technique in terms of performance. Some examples: Natural Language Processing (NLP) | Computer Vision | Medicine | Biology | Image generation | Recommendation systems | Playing games | Robotics | . | . Neural Networks: A Brief History . McCulloch, Pitts realized that simplified model of a real neuron could be represented using simple addition and thresholding. Further reading: A logical calculus of the ideas immanent in nervous activity, McCulloch, Pitts. | Rosenblatt further built on this work to develop a machine that could learn (Mark I Perceptron). Further reading: The Design of an Intelligent Automaton, Rosenblatt. | Minsky and Papert states about Rosenblatt&#39;s invention that a single layer of these devices was unable to learn some simple but crtical mathematical function such as XOR. They also showed that with multiple layers these limitations could be addressed. Only first insight was widely recognized and neural networks were abandoned for two decades because of this misperception. Further reading: Perceptrons | Pivotal work in neural networks by Rumelhart, McClellan. In their book Parallel Distributed Processing (PDP), they propose that PDP requires: A set of processing units | A state of activation | An output function for each unit | A pattern of connectivity among units | A propagation rule for propagating patterns of activities through the network of connectivities | An activation rule for combining inputs impinging on a unit with the current state of that unit to produce an output for the unit | A learning rule whereby patterns of connectivity are modified by experience | An environment within which the system must operate | | Although a second layer can approximate all functions, this results in a slow neural network. In more recent work, more layers of neurons are being used, as a consequence of which performance and speed has improved and neural networks are living up to their potential. | . How to Learn Deep Learning (and anything else) . Top down by doing rather than by learning (same way in which you would learn sports) | Theory comes later when needed and after you have more of a context through experience | Apply what you learn to personal project, be tenacious | Do a little bit of a lot of the time rather than a lot a little bit of the time | . The Software: PyTorch, fastai, and Jupyter . PyTorch is fastest growing deep learning library and widely adopted in research &rarr; leading indicator for industry adoption | PyTorch works best as low-level foundation library, fastai most popular high-level library, on top of PyTorch | Further reading: fastai: A Layered API for Deep Learning, Howard, Gugger | Which deep learning library you learn does not matter that much, switching is a matter of days | . Your First Model . To train Deep Learning models, an NVIDIA GPU is needed. | GPU = Graphics Processing Unit &rarr; handles thousands of single tasks at the same time. Initially used for rendering 3D environments on computers, it can speed up Deep Learning calculations hundreds of times compared to regular CPUs. | How do we know if a model is any good? Error rate: proportion of incorrectly identified images | . | . What is Machine Learning? . Deep learning is an area in the more general discipline of machine learning | In machine learning, the computer figures out (i.e. learns) how to do a task, rather than the programmer explicitly programming it to perform that task | Further reading: Artificial Intelligence: A Frontier of Automation, Samuel | . What is a Neural Network? . A neural network is a mathematical function that is extremely flexibile depending on its weight | The universal approximation theorem shows that this function can solve any problem to any level of accuracy, in theory | To solve a problem with a neural network model, a mechanism is needed for automatically updating the weights such that the model approximates the solution for that problem. Such a mechanism exists, it is called stochastic gradient descent (SGD). | For an image recognition problem for instance: The inputs are the images | The weights are the weights in the neural net | The results are the values calculated by the neural net (e.g. &#39;cat&#39; or &#39;dog&#39; if we are trying to build a cat/dog classifier) | The performance is the accuracy at predicting the correct answers | . | . A Bit of Deep Learning Jargon . Model = Architecture | Weights = Parameters | Predictions are calculated from the independent variable , which is the data excluding the labels | The results are called predictions | The measure of performance is called the loss | The loss depends not only on predictions, but also the correct labels (aka targets or dependent variable) | . Limitations Inherent to Machine Learning . Limitations: Model cannot be created without data | Model can only learn to operate on patterns in input data used to train it | Only predictions, not recommended actions | Data must also have labels | . | A model can interact with its environment. Example of predictive policing: Model based on data indicates where a lot of arrests were made in the past | Law enforcement focuses policing in those areas, resulting in more arrests | Data fed back to model &rarr; positive feedback loop, i.e. the more the model is used, the more biased data becomes | . | . How Our Image Recognized Works . from fastai.vision.all import * # imports library path = untar_data(URLs.PETS)/&#39;images&#39; # downloads standard dataset from fast.ai datasets collection def is_cat(x): return x[0].isupper() # function which labels cats based on filename rule dls = ImageDataLoaders.from_name_func( # class for loading in image data path, # location of data get_image_files(path), # ? valid_pct=0.2, # validation set percentage seed=42, # random seed label_func=is_cat, # what function to use to label data item_tfms=Resize(224)) # transformation per item (there is also batch_tfms) learn = vision_learner(dls, resnet34, metrics=error_rate) # convolutional neural network (CNN) + architecture . Classification: predict class or category from number of discrete possibilities | Regression: predict numeric quantities | fastai will always show model accuracy based on validation set alone, not training set | If you overfit your training data, your training set accuracy will improve, but validation set accuracy will suffer. | Overfitting is the single most important and challenging issue Overfitting happens when your algorithm memorizes the data | There are techniques to mitigate/avoid overfitting. These techniques should only be employed when overfitting is observed. | . | Validation set: when you train a model, you must always have both a training and validation set. Accuracy must be measured on validation set. | By default fastai has validation set percentage of 20%. | In practice picking an architecture is not very important. It is more of an academic subject. There are some standard architectures that work most of the time, like ResNet for computer vision problems. | The 34 in ResNet34 refers to the number of layers in the architecture. | If a neural network has more layers: it takes longer to train and is more prone to overfitting (i.e. you can&#39;t train them for as many epochs before the accuracy on the validation set starts getting worse.) | on the other hand, when using more data, more layers can yield better accuracy | . | What is a metric? A function that measures quality of model&#39;s predictions using validation set (it is printed at end of each epoch). | Usually the metric is error rate (percentage of images classified incorrectly). Other common metric is accuracy (1.0-errror_rate). | fastai provides many more metrics | Difference between metric and loss: Loss is a measurement of performance that training system uses to update weights automatically (i.e. it is used for SGD) | Metric is for human consumption, easy to understand and hews as closely as possible to what you want the model to do | . | . | Pretrained models have been trained on some other dataset. You should nearly always use a pretrained model, because you will have a better starting point. | When using a pretrained model, vision_learner will remove last layer, since it is customized to original training task, and replace with one or more layers with randomized weights. This part of the model is known as the head. | Using pretrained models allows for training more accurate models, more quickly, with less data, and less time and money. Nevertheless, it is not recognized in academia as much as it should. | Using pretrained model for a task different to what it was originally trained for is known as transfer learning. | Fine-tuning is a transfer learning technique where the parameters of a pretrained model are updated by training for additional epochs using a different task to that used for pretraining. | When calling fine-tune, fastai applies following tricks: Use one epoch to fit just those parts of the model necessary to get the new random head to work correctly with the dataset | Use number of epochs requested, updating weights of later layers (especially head) faster than earlier layers. | | An epoch is one complete pass through the dataset. After each epoch, following is printed: Epoch number | training and validation set losses (measure of performance) | requested metrics (e.g. error rate) | . | . What Our Image Recognizer Learned . Deep learning results are often regarded as a &#39;black box&#39;, i.e. difficult to interpret/explain. However there is a lot of research about how to inspect deep learning models and gain rich insights from them. | Further reading: Visualizing and Understanding Convolutional Networks, Zeiler, Fergus | . Image Recognizer Can Tackle Non-Image Tasks . You can represent different things as an image and then use an image recognizer. For instance by converting sound into a spectogram. It is important that when doing this, the components that you would like the deep learning model to recognize, are easily detectable. A good rule of thumb is that if a human eye can detect it, a deep learning model should be able to do so too. | . Deep Learning Is Not Just For Image Classification . Another application of deep learning is called segmentation. This is about identifying what each pixel in an image belongs to. It is used for instance in autonomous driving. | . Example of training a segmentation model using a subset of Camvid dataset shown below. Code is very similar to previous cat/dog classifier. | . path = untar_data(URLs.CAMVID_TINY) dls = SegmentationDataLoaders.from_label_func( path, bs=8, fnames = get_image_files(path/&quot;images&quot;), label_func = lambda o: path/&#39;labels&#39;/f&#39;{o.stem}_P{o.suffix}&#39;, codes = np.loadtxt(path/&#39;codes.txt&#39;, dtype=str) ) learn = unet_learner(dls, resnet34) learn.fine_tune(8) learn.show_results(max_n=6, figsize=(7,8)) . Example of deep learning NLP model (note to self: could not get it to work. Revisit later to troubleshoot.) | . from fastai.text.all import * dls = TextDataLoaders.from_folder(untar_data(URLs.IMDB), valid=&#39;test&#39;, bs=16) learn = text_classifier_learner(dls, AWD_LSTM, drop_mult=0.5, metrics=accuracy) learn.fine_tune(4, 1e-2) . Jupyter . Restart notebook: hit 00 in command mode to restart notebook (wipes internal state and restarts) | Check documentation fastai: doc([method name]), example: doc(learn.predict) | . Datasets: Food for Models . There are curated datasets that serve as academic baselines, i.e. they are used in research to compare model performance | In practice deep learning practitioners use such datasets, but in order to iterate quickly, they use representative subsets of such datasets. | . Validation Sets and Test Sets . Goal of a model is to make predictions about data. But if we train model with all our data, we won&#39;t be able to tell how well it performs outside of the training data. Therefore we withhold a part of the data and call that part the validation set. The rest is called the training set. | As we explore different models, there are a lot of variables we play around with. For example: network architecture, learning rates, data augmentation strategies, and so on. These are known as hyperparameters. | Hyperparameter tuning can also leads to overfitting. Because of this, we introduce an even more highly reserved dataset, the test set. It is only to be used at the very end of our efforts. | . Use Judgment in Defining Test Sets . Randomly selecting a test set is not always a good idea. For instance, for a time series, you would usually want to predict what will happen in the future. | In general you don&#39;t want your model to be trained based on peculiarities/specifics of the training dataset (e.g. Kaggle fisheries competition, Kaggle distracted driver competition) | . Questionnaire . Do you need these for deep learning? Lots of math T / F | Lots of data T / F | Lots of expensive computers T / F | A PhD T / F | . | Name five areas where deep learning is now the best in the world. NLP, computer vision, medicine, biology, image recommendation systems, robotics | . | What was the name of the first device that was based on the principle of the artificial neuron? Mark I Perceptron (made by Rosenblatt) | Based on the book of the same name, what are the requirements for parallel distributed processing (PDP)? A set of processing units | A state of activation | An output function for each unit | A pattern of connectivity among units | A propagation rule for propagating patterns of activities through the network of connectivities | An activation rule for combining inputs impinging on a unit with the current state of that unit to produce an output for the unit | A learning rule whereby patterns of connectivity are modified by experience | An environment within which the system must operate | | What were the two theoretical misunderstandings that held back the field of neural networks? Simple functions (like XOR) cannot be modelled | ? | | What is a GPU? Graphics Processing Unit, also known as a graphics card, good at performing many tasks at the same time (matrix multiplication) | . | Open a notebook and execute a cell containing: 1+1. What happens? | Follow through each cell of the stripped version of the notebook for this chapter. Before executing each cell, guess what will happen. | Complete the Jupyter Notebook online appendix. | Why is it hard to use a traditional computer program to recognize images in a photo? Too much variation in input data (various images), too many rules to program, intractable | . | What did Samuel mean by &quot;weight assignment&quot;? Choice of parameter values | . | What term do we normally use in deep learning for what Samuel called &quot;weights&quot;? parameters | . | Draw a picture that summarizes Samuel&#39;s view of a machine learning model. | Why is it hard to understand why a deep learning model makes a particular prediction? ? | . | What is the name of the theorem that shows that a neural network can solve any mathematical problem to any level of accuracy? Universal Approximation Theorem | . | What do you need in order to train a model? labeled data | . | How could a feedback loop impact the rollout of a predictive policing model? Based on the data the model could predict certain areas have a higher crime rate, if policing efforts are then focused in those areas, it will lead to more arrests, further reinforcing the model (positive feedback) | . | Do we always have to use 224×224-pixel images with the cat recognition model? No, it is a choice (a hyperparameter) | . | What is the difference between classification and regression? Classification is about predicting categories or classes and regression is about predicting numberic quantities | . | What is a validation set? What is a test set? Why do we need them? Validation set is used to evaluate model accuracy and mitigate overfitting during training | Test set is a more exclusive dataset only to be used at the very end to mitigate overfitting due to hyperparameter tuning | . | What will fastai do if you don&#39;t provide a validation set? Take 20% of the data randomly and make it the validation set | . | Can we always use a random sample for a validation set? Why or why not? No, you may not be able to prevent overfitting that way in all cases. For example with time series. | . | What is overfitting? Provide an example. It is when your model learns idiosyncrasies from the training data and therefore does not generalize to data it has not seen before. Example: if you have a computer vision model that tries to determine if an image is that of a cat, but you only have images of the same cat, it will not generalize well to other cats. The model will learn the shape, color, and other specifics of that cat alone. | . | What is a metric? How does it differ from &quot;loss&quot;? A metric is a measure of accuracy of the model. It is for human consumption to determine how well our model is performing. Loss on the other hand is a measure used by the deep learning model to tune the parameters. It is used by SGD. | . | How can pretrained models help? Less data, more accuracy, less time/money | . | What is the &quot;head&quot; of a model? Top layer, predicts what we are interested in | . | What kinds of features do the early layers of a CNN find? How about the later layers? Early: lines, gradients, later: patterns, shapes | . | Are image models only useful for photos? No, you can represent different data as images and use an image model (e.g. spectogram for audio) | . | What is an &quot;architecture&quot;? The deep learning network | . | What is segmentation? Identifying what each pixel of an image is a pixel of | . | What is y_range used for? When do we need it? Range of our target, we need it when predicting a continuous number (rather than a category) | . | What are &quot;hyperparameters&quot;? A parameter that is used to control the learning process (e.g. model architecture, learning rate, batch size, etc.) | . | What&#39;s the best way to avoid failures when using AI in an organization? Test set that machine learning engineers do not get to use | . |",
            "url": "https://kemal-nl.github.io/personal-blog/fast-ai-book/2022/08/11/fastai-book-chapter-1.html",
            "relUrl": "/fast-ai-book/2022/08/11/fastai-book-chapter-1.html",
            "date": " • Aug 11, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Live Coding Session 2",
            "content": "Relevant Material . Live Coding Session 2 Forum . . Note: These are my personal notes. They are not meant to be a comprehensive summary, but rather the things I wanted to note down for myself to refer to at a later point. . At the end of this lesson you will have: . learned how to use git and github at a basic level (cloning, forking, committing, pushing, gitignor) | learned how to use SSH to use a computer remotely | learned how to use tmux for improved productivity by using multiple terminals | learned how to use Jupyter Notebooks | installed fastai | . Notes . Git and Github . Git is a version control system with which you can create a repository. Easy to switch to older versions (i.e. &#39;backups&#39;) | Github is a website that hosts git repositories | Cloning repositories: git clone [git url] You can do it with HTTP, but cannot commit without logging into repository | Alternatively you can use SSH | . | If you want to experiment with a repository you can fork it via github. Then you can clone it and plan around with it locally. | Basic workflow: git status | git add . | git commit -m &quot;Updated something&quot; | git push | . | . SSH . SSH is a way of logging into remote computers | It consists of a key-pair: public key and a prviate key Private key is proof of identity (should be kept secret) | Public key says if you can prove identity associated with private key, you can log in | . | To generate SSH keys, input in terminal: ssh-keygen | . tmux . Allows for multiple terminals inside one terminal window | Shortcuts always start with CTRL+B: Divide current window vertically: CTRL+B+% | Divide current window horizontally: CTRL+B+&quot; | Close window: CTRL+B+D | Move around: CTRL+B+&darr;&uarr;&larr;&rarr; | Toggle zoom (focus on one window): CTRL+B+Z | Attach (starts your session from where it left off after CTRL+B+D): tmux a | . | . Jupyter . Show documentation for a function: SHIFT+TAB | . Install fast.ai . Install: mamba install -c fastchan fastai | Alternatively you can also install fastbook which includes fastai: mamba install -c fastchan fastbook | .",
            "url": "https://kemal-nl.github.io/personal-blog/live-coding/2022/08/09/fastai-livecoding-2.html",
            "relUrl": "/live-coding/2022/08/09/fastai-livecoding-2.html",
            "date": " • Aug 9, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "Live Coding Session 1",
            "content": "Relevant Material . Live Coding Session 1 Forum . . Note: These are my personal notes. They are not meant to be a comprehensive summary, but rather the things I wanted to note down for myself to refer to at a later point. . At the end of this lesson you will have: . Installed Windows Subsystem for Linux (WSL) and understood why it is needed | Learned how to use Linux shell and some basic commands (e.g. navigate around the file system, create/delete files, view contents of text files, modify permissions, some shortcuts/tips/tricks like aliases and bash scripts) | Installed conda/mambaforge and understood why it is needed and what its advantages are over pip and conda | Learned about using bash scripts to automate certain tasks in Linux (e.g. installing packages) | Installed Python with mamba | Installed IPython with mamba | Installed Jupyter Lab with mamba | Installed PyTorch with mamba | . Notes . Prerequisites . Install Windows Subsystem for Linux (WSL) by typing into Powershell (run as admin): wsl --install For more details refer to guide by Microsoft | . | Check whether Python and Jupyter are installed: python and jupyter Output (e.g. for Python) should be: Command &#39;python&#39; not found | There probably is a system version of Python. You do not want to be using this since it may interfere with the OS behavior. | . | . Install conda/mambaforge manually . Make downloads directory inside home directory: mkdir downloads | Download mambaforge: wget https://github.com/conda-forge/miniforge/releases/latest/download/Mambaforge-Linux-x86_64.sh | Install mambaforge using bash: bash Mambaforge-Linux-x86_64.sh To ensure python environment is set up when starting terminal: Do you wish the installer to initialize Mambaforge by running conda init? [yes|no] &rarr; yes | . | After installing and restarting shell, terminal should mention (base) and which python should show a python directory in the mambaforge directory | Install conda/mambaforge with bash script from fastai/fastsetup . If you followed steps to manually install conda/mambaforge: Remove mambaforge from home directory: rm -rf mambaforge | Remove mambaforge installer from downloads directory: rm -rf | Restart shell | . | Go to fastsetup github repo and click on setup-conda.sh. Subsequently click on raw and copy url. Download it: wget https://raw.githubusercontent.com/fastai/fastsetup/master/setup-conda.sh | Run it: bash setup-conda.sh or ./setup-conda.sh If you get Permission Denied then: Inspect permissions: ls -l (output needs to contain &#39;x&#39; which stands for permission to execute) | Change permission: chmod u+x setup-conda.sh | . | . | Install other packages with mamba . Python libraries can be installed with: conda, pip, mamba conda vs mamba: 2 ways of doing same thing, compatible with each other, mamba is faster | prefer to use mamba, but usually documentation refers to conda (more established, around longer) | advantage of conda/mamba over pip is that the dependencies are also installed correctly. If you use pip to install pytorch for instance, you need to install other stuff as well, whereas conda/mamba take care of installing everything you need correctly. | . | Never install stuff through apt, that is system stuff | . Install ipython: mamba install ipython | Install pytorch: Go to pytorch.org &rarr; Get Started &rarr; Start Locally | Pick options: Stable, Linux, Conda, Python, CPU | Copy command, paste into terminal, change conda to mamba: mamba install pytorch torchvision torchaudio cpuonly -c pytorch -c pytorch refers to the channel of pytorch | check if installed correctly by starting ipython and subsequently typing import torch. | . | | Install jupyerlab: mamba install jupyterlab Start Jupyter Lab: jupyter lab | This will start jupyter server. It will try to open browser, but there is no browser in Ubuntu, so it will give error. But link that is returned in Terminal can be Control+clicked to open browser in Windows. | If you do not want the error, add flag: jupyter lab --no-browser | . | Useful tips/commands in Linux . Check where Python is installed: which python | Print working directory you are in: pwd | Navigate to home directory: cd or cd ~ | Make directory: mkdir [directory name] | Delete directory (recursive and force delete): rm -rf [directory name] | Move directory: mv | List contents of directory ls [-flags] Flags Long form: l | Human readable: h | All (i.e. including hidden ones): a | Sorted by date modified: t | Possible to combine flags, e.g.: ls -lhat | . | Look at a text file: less [filename] | Restart shell: sudo -u [user] -i | Change permission: chmod u+x [filename] (u=user, x=execute permission) | Close terminal program: Control+D | Shortcut to run command: press UP arrow to cycle through previous commands All your terminal inputs are stored in the home folder in a file named .bash_history. This is convenient for creating bash scripts. Note that .bash_history is overwritten. If you have multiple bash sessions, only last one will survive. | . | Search through your previous terminal commands: Control+R | Run last command starting with some letters: ![letters] e.g. if last command you ran starting with ju was jupyter lab --no-browser, then !ju would run that command | . | Run last command: !! can use echo to print it | . | Jump to: end of line: Control+E | start of line: Control+A | end/start of a word : Control+LEFT/RIGHT | . | Define alias (i.e. a shortcut for a command): alias [alias]=&quot;[command]&quot; e.g. alias jl=&quot;jupyter lab --no-browser&quot; | if you want it to persist across sessions, need to add it to .bashrc or to .bash_aliases | . | . Useful tip for ipython . By pressing TAB after typing a library name, you get to see all the functions (including arguments), submodules, etc. | .",
            "url": "https://kemal-nl.github.io/personal-blog/live-coding/2022/08/05/fastai-livecoding-1.html",
            "relUrl": "/live-coding/2022/08/05/fastai-livecoding-1.html",
            "date": " • Aug 5, 2022"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Hi, my name is Kemal. . I am interested in learning Machine Learning. I have decided to follow the course Practical Deep Learning for Coders by Jeremy Howard. With this blog I intend to apply the principle of learning in public and follow the advice of Rachel Thomas in Why you (yes, you) should blog. This goes against my inclination as I typically am not one to share my work in public. However this is my attempt at changing that. What you will find on my blog are my notes and project work for the fast.ai course. .",
          "url": "https://kemal-nl.github.io/personal-blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://kemal-nl.github.io/personal-blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}