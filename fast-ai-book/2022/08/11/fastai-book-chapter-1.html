<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Book Chapter 1 | fast.ai notes</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Book Chapter 1" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="My personal notes for the fast.ai book Chapter 1." />
<meta property="og:description" content="My personal notes for the fast.ai book Chapter 1." />
<link rel="canonical" href="https://kemal-nl.github.io/personal-blog/fast-ai-book/2022/08/11/fastai-book-chapter-1.html" />
<meta property="og:url" content="https://kemal-nl.github.io/personal-blog/fast-ai-book/2022/08/11/fastai-book-chapter-1.html" />
<meta property="og:site_name" content="fast.ai notes" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-08-11T00:00:00-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Book Chapter 1" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-08-11T00:00:00-05:00","datePublished":"2022-08-11T00:00:00-05:00","description":"My personal notes for the fast.ai book Chapter 1.","headline":"Book Chapter 1","mainEntityOfPage":{"@type":"WebPage","@id":"https://kemal-nl.github.io/personal-blog/fast-ai-book/2022/08/11/fastai-book-chapter-1.html"},"url":"https://kemal-nl.github.io/personal-blog/fast-ai-book/2022/08/11/fastai-book-chapter-1.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/personal-blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://kemal-nl.github.io/personal-blog/feed.xml" title="fast.ai notes" /><link rel="shortcut icon" type="image/x-icon" href="/personal-blog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/personal-blog/">fast.ai notes</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/personal-blog/about/">About Me</a><a class="page-link" href="/personal-blog/search/">Search</a><a class="page-link" href="/personal-blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Book Chapter 1</h1><p class="page-description">My personal notes for the fast.ai book Chapter 1.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-08-11T00:00:00-05:00" itemprop="datePublished">
        Aug 11, 2022
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      16 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/personal-blog/categories/#fast-ai-book">fast-ai-book</a>
        
      
      </p>
    

    
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul id="toc" class="section-nav">
<li class="toc-entry toc-h1"><a href="#Relevant-Material">Relevant Material </a></li>
<li class="toc-entry toc-h1"><a href="#Notes">Notes </a>
<ul>
<li class="toc-entry toc-h2"><a href="#Deep-Learning-is-for-Everyone">Deep Learning is for Everyone </a></li>
<li class="toc-entry toc-h2"><a href="#Neural-Networks:-A-Brief-History">Neural Networks: A Brief History </a></li>
<li class="toc-entry toc-h2"><a href="#How-to-Learn-Deep-Learning-(and-anything-else)">How to Learn Deep Learning (and anything else) </a></li>
<li class="toc-entry toc-h2"><a href="#The-Software:-PyTorch,-fastai,-and-Jupyter">The Software: PyTorch, fastai, and Jupyter </a></li>
<li class="toc-entry toc-h2"><a href="#Your-First-Model">Your First Model </a></li>
<li class="toc-entry toc-h2"><a href="#What-is-Machine-Learning?">What is Machine Learning? </a></li>
<li class="toc-entry toc-h2"><a href="#What-is-a-Neural-Network?">What is a Neural Network? </a></li>
<li class="toc-entry toc-h2"><a href="#A-Bit-of-Deep-Learning-Jargon">A Bit of Deep Learning Jargon </a></li>
<li class="toc-entry toc-h2"><a href="#Limitations-Inherent-to-Machine-Learning">Limitations Inherent to Machine Learning </a></li>
<li class="toc-entry toc-h2"><a href="#How-Our-Image-Recognized-Works">How Our Image Recognized Works </a></li>
<li class="toc-entry toc-h2"><a href="#What-Our-Image-Recognizer-Learned">What Our Image Recognizer Learned </a></li>
<li class="toc-entry toc-h2"><a href="#Image-Recognizer-Can-Tackle-Non-Image-Tasks">Image Recognizer Can Tackle Non-Image Tasks </a></li>
<li class="toc-entry toc-h2"><a href="#Deep-Learning-Is-Not-Just-For-Image-Classification">Deep Learning Is Not Just For Image Classification </a></li>
<li class="toc-entry toc-h2"><a href="#Jupyter">Jupyter </a></li>
<li class="toc-entry toc-h2"><a href="#Datasets:-Food-for-Models">Datasets: Food for Models </a></li>
<li class="toc-entry toc-h2"><a href="#Validation-Sets-and-Test-Sets">Validation Sets and Test Sets </a></li>
<li class="toc-entry toc-h2"><a href="#Use-Judgment-in-Defining-Test-Sets">Use Judgment in Defining Test Sets </a></li>
<li class="toc-entry toc-h2"><a href="#Questionnaire">Questionnaire </a></li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2022-08-11-fastai-book-chapter-1.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Relevant-Material">
<a class="anchor" href="#Relevant-Material" aria-hidden="true"><span class="octicon octicon-link"></span></a>Relevant Material<a class="anchor-link" href="#Relevant-Material"> </a>
</h1>
<p><a href="https://github.com/fastai/fastbook/blob/master/01_intro.ipynb">fast.ai Book Chapter 1 (Jupyter Notebook)</a></p>
<p><a href="https://www.amazon.com/Deep-Learning-Coders-fastai-PyTorch/dp/1492045527">fast.ai Book</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash">
    <svg class="octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>These are my personal notes. They are not meant to be a comprehensive summary, but rather the things I wanted to note down for myself to refer to at a later point.
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Notes">
<a class="anchor" href="#Notes" aria-hidden="true"><span class="octicon octicon-link"></span></a>Notes<a class="anchor-link" href="#Notes"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Deep-Learning-is-for-Everyone">
<a class="anchor" href="#Deep-Learning-is-for-Everyone" aria-hidden="true"><span class="octicon octicon-link"></span></a>Deep Learning is for Everyone<a class="anchor-link" href="#Deep-Learning-is-for-Everyone"> </a>
</h2>
<ul>
<li>It is a commonly held belief that in order for you to do deep learning successfully, you need:<ul>
<li>anything beyond high school math</li>
<li>inordinate amounts of data that ordinary individuals do not have access too</li>
<li>prohibitively expensive hardware</li>
</ul>
</li>
<li>What is deep learning essentially?<ul>
<li>Technique to extract and transform data</li>
<li>By making use of multiple layers of neural networks. Each of these layers takes inputs from previous layers and progressively refines them. </li>
<li>Layers are trained by algorithms that minimizes their errors and improves accuracy.</li>
</ul>
</li>
<li>Due to Deep Learning's versatility and power, its application space is vast and often it is the dominant technique in terms of performance. Some examples:<ul>
<li>Natural Language Processing (NLP)</li>
<li>Computer Vision</li>
<li>Medicine</li>
<li>Biology</li>
<li>Image generation</li>
<li>Recommendation systems</li>
<li>Playing games</li>
<li>Robotics</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Neural-Networks:-A-Brief-History">
<a class="anchor" href="#Neural-Networks:-A-Brief-History" aria-hidden="true"><span class="octicon octicon-link"></span></a>Neural Networks: A Brief History<a class="anchor-link" href="#Neural-Networks:-A-Brief-History"> </a>
</h2>
<ul>
<li>McCulloch, Pitts realized that simplified model of a real neuron could be represented using simple addition and thresholding. Further reading: <em>A logical calculus of the ideas immanent in nervous activity, McCulloch, Pitts</em>.</li>
<li>Rosenblatt further built on this work to develop a machine that could learn (Mark I Perceptron). Further reading: <em>The Design of an Intelligent Automaton, Rosenblatt</em>.</li>
<li>Minsky and Papert states about Rosenblatt's invention that a single layer of these devices was unable to learn some simple but crtical mathematical function such as XOR. They also showed that with multiple layers these limitations could be addressed. Only first insight was widely recognized and neural networks were abandoned for two decades because of this misperception. Further reading: <em>Perceptrons</em>
</li>
<li>Pivotal work in neural networks by Rumelhart, McClellan. In their book <em>Parallel Distributed Processing (PDP)</em>, they propose that PDP requires:<ol>
<li>A set of <em>processing units</em>
</li>
<li>A state of <em>activation</em>
</li>
<li>An <em>output function</em> for each unit</li>
<li>A <em>pattern of connectivity</em> among units</li>
<li>A <em>propagation rule</em> for propagating patterns of activities through the network of connectivities</li>
<li>An <em>activation rule</em> for combining inputs impinging on a unit with the current state of that unit to produce an output for the unit</li>
<li>A <em>learning rule</em> whereby patterns of connectivity are modified by experience</li>
<li>An <em>environment</em> within which the system must operate</li>
</ol>
</li>
<li>Although a second layer can approximate all functions, this results in a slow neural network. In more recent work, more layers of neurons are being used, as a consequence of which performance and speed has improved and neural networks are living up to their potential.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="How-to-Learn-Deep-Learning-(and-anything-else)">
<a class="anchor" href="#How-to-Learn-Deep-Learning-(and-anything-else)" aria-hidden="true"><span class="octicon octicon-link"></span></a>How to Learn Deep Learning (and anything else)<a class="anchor-link" href="#How-to-Learn-Deep-Learning-(and-anything-else)"> </a>
</h2>
<ul>
<li>Top down by <em>doing</em> rather than by learning (same way in which you would learn sports)</li>
<li>Theory comes later when needed and after you have more of a context through experience</li>
<li>Apply what you learn to personal project, be tenacious</li>
<li>Do a little bit of a lot of the time rather than a lot a little bit of the time</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="The-Software:-PyTorch,-fastai,-and-Jupyter">
<a class="anchor" href="#The-Software:-PyTorch,-fastai,-and-Jupyter" aria-hidden="true"><span class="octicon octicon-link"></span></a>The Software: PyTorch, fastai, and Jupyter<a class="anchor-link" href="#The-Software:-PyTorch,-fastai,-and-Jupyter"> </a>
</h2>
<ul>
<li>
<strong>PyTorch</strong> is fastest growing deep learning library and widely adopted in research → leading indicator for industry adoption</li>
<li>PyTorch works best as low-level foundation library, <strong>fastai</strong> most popular high-level library, on top of PyTorch</li>
<li>Further reading: <em>fastai: A Layered API for Deep Learning, Howard, Gugger</em>
</li>
<li>Which deep learning library you learn does not matter that much, switching is a matter of days</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Your-First-Model">
<a class="anchor" href="#Your-First-Model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Your First Model<a class="anchor-link" href="#Your-First-Model"> </a>
</h2>
<ul>
<li>To train Deep Learning models, an NVIDIA GPU is needed.</li>
<li>
<strong>GPU = Graphics Processing Unit</strong> → handles thousands of single tasks at the same time. Initially used for rendering 3D environments on computers, it can speed up Deep Learning calculations hundreds of times compared to regular CPUs.</li>
<li>How do we know if a model is any good?<ul>
<li>
<strong>Error rate</strong>: proportion of incorrectly identified images</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="What-is-Machine-Learning?">
<a class="anchor" href="#What-is-Machine-Learning?" aria-hidden="true"><span class="octicon octicon-link"></span></a>What is Machine Learning?<a class="anchor-link" href="#What-is-Machine-Learning?"> </a>
</h2>
<ul>
<li>Deep learning is an area in the more general discipline of <strong>machine learning</strong>
</li>
<li>In machine learning, the computer figures out (i.e. learns) how to do a task, rather than the programmer explicitly programming it to perform that task</li>
<li>Further reading: <em>Artificial Intelligence: A Frontier of Automation, Samuel</em>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="What-is-a-Neural-Network?">
<a class="anchor" href="#What-is-a-Neural-Network?" aria-hidden="true"><span class="octicon octicon-link"></span></a>What is a Neural Network?<a class="anchor-link" href="#What-is-a-Neural-Network?"> </a>
</h2>
<ul>
<li>A neural network is a mathematical function that is extremely flexibile depending on its weight</li>
<li>The <strong>universal approximation theorem</strong> shows that this function can solve any problem to any level of accuracy, in theory</li>
<li>To solve a problem with a neural network model, a mechanism is needed for <strong>automatically updating the weights</strong> such that the model approximates the solution for that problem. Such a mechanism exists, it is called <strong>stochastic gradient descent (SGD)</strong>.</li>
<li>For an image recognition problem for instance:<ul>
<li>The <strong>inputs</strong> are the images</li>
<li>The <strong>weights</strong> are the weights in the neural net</li>
<li>The <strong>results</strong> are the values calculated by the neural net (e.g. 'cat' or 'dog' if we are trying to build a cat/dog classifier)</li>
<li>The <strong>performance</strong> is the accuracy at predicting the correct answers</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="A-Bit-of-Deep-Learning-Jargon">
<a class="anchor" href="#A-Bit-of-Deep-Learning-Jargon" aria-hidden="true"><span class="octicon octicon-link"></span></a>A Bit of Deep Learning Jargon<a class="anchor-link" href="#A-Bit-of-Deep-Learning-Jargon"> </a>
</h2>
<ul>
<li>Model = <strong>Architecture</strong>
</li>
<li>Weights = <strong>Parameters</strong>
</li>
<li>
<strong>Predictions</strong> are calculated from the <strong>independent variable</strong> , which is the data excluding the labels</li>
<li>The <em>results</em> are called <strong>predictions</strong>
</li>
<li>The measure of <em>performance</em> is called the <strong>loss</strong>
</li>
<li>The loss depends not only on predictions, but also the correct <strong>labels</strong> (aka <strong>targets</strong> or <strong>dependent variable</strong>)</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Limitations-Inherent-to-Machine-Learning">
<a class="anchor" href="#Limitations-Inherent-to-Machine-Learning" aria-hidden="true"><span class="octicon octicon-link"></span></a>Limitations Inherent to Machine Learning<a class="anchor-link" href="#Limitations-Inherent-to-Machine-Learning"> </a>
</h2>
<ul>
<li>Limitations:<ul>
<li>Model cannot be created without data</li>
<li>Model can only learn to operate on patterns in input data used to train it</li>
<li>Only predictions, not recommended actions</li>
<li>Data must also have labels</li>
</ul>
</li>
<li>A model can interact with its environment. Example of predictive policing:<ul>
<li>Model based on data indicates where a lot of arrests were made in the past</li>
<li>Law enforcement focuses policing in those areas, resulting in more arrests</li>
<li>Data fed back to model → positive feedback loop, i.e. the more the model is used, the more biased data becomes</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="How-Our-Image-Recognized-Works">
<a class="anchor" href="#How-Our-Image-Recognized-Works" aria-hidden="true"><span class="octicon octicon-link"></span></a>How Our Image Recognized Works<a class="anchor-link" href="#How-Our-Image-Recognized-Works"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">fastai.vision.all</span> <span class="kn">import</span> <span class="o">*</span>             <span class="c1"># imports library</span>

<span class="n">path</span> <span class="o">=</span> <span class="n">untar_data</span><span class="p">(</span><span class="n">URLs</span><span class="o">.</span><span class="n">PETS</span><span class="p">)</span><span class="o">/</span><span class="s1">'images'</span>       <span class="c1"># downloads standard dataset from fast.ai datasets collection</span>

<span class="k">def</span> <span class="nf">is_cat</span><span class="p">(</span><span class="n">x</span><span class="p">):</span> <span class="k">return</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">isupper</span><span class="p">()</span>        <span class="c1"># function which labels cats based on filename rule</span>

<span class="n">dls</span> <span class="o">=</span> <span class="n">ImageDataLoaders</span><span class="o">.</span><span class="n">from_name_func</span><span class="p">(</span>      <span class="c1"># class for loading in image data </span>
    <span class="n">path</span><span class="p">,</span>                                   <span class="c1"># location of data</span>
    <span class="n">get_image_files</span><span class="p">(</span><span class="n">path</span><span class="p">),</span>                  <span class="c1"># ?</span>
    <span class="n">valid_pct</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>                          <span class="c1"># validation set percentage</span>
    <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>                                <span class="c1"># random seed</span>
    <span class="n">label_func</span><span class="o">=</span><span class="n">is_cat</span><span class="p">,</span>                      <span class="c1"># what function to use to label data</span>
    <span class="n">item_tfms</span><span class="o">=</span><span class="n">Resize</span><span class="p">(</span><span class="mi">224</span><span class="p">))</span>                  <span class="c1"># transformation per item (there is also batch_tfms)</span>

<span class="n">learn</span> <span class="o">=</span> <span class="n">vision_learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">resnet34</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">error_rate</span><span class="p">)</span>   <span class="c1"># convolutional neural network (CNN) + architecture</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>
<strong>Classification</strong>: predict class or category from number of discrete possibilities</li>
<li>
<strong>Regression</strong>: predict numeric quantities</li>
<li>fastai will always show model <strong>accuracy based on validation set alone, not training set</strong>
</li>
<li>If you <strong>overfit</strong> your training data, your training set accuracy will improve, but validation set accuracy will suffer.</li>
<li>
<strong>Overfitting is the single most important and challenging issue</strong><ul>
<li>Overfitting happens when your algorithm memorizes the data </li>
<li>There are techniques to mitigate/avoid overfitting. These techniques should only be employed when overfitting is observed.</li>
</ul>
</li>
<li>Validation set: when you train a model, you must always have both a training and validation set. <strong>Accuracy must be measured on validation set.</strong> </li>
<li>By default fastai has validation set percentage of 20%.</li>
<li>
<strong>In practice picking an architecture is not very important.</strong> It is more of an academic subject. There are some standard architectures that work most of the time, like <strong>ResNet</strong> for computer vision problems.</li>
<li>The 34 in <strong>ResNet34</strong> refers to the number of layers in the architecture.</li>
<li>If a neural network has more layers:<ul>
<li>it takes longer to train and is more prone to overfitting (i.e. you can't train them for as many epochs before the accuracy on the validation set starts getting worse.)</li>
<li>on the other hand, when using more data, more layers can yield better accuracy</li>
</ul>
</li>
<li>What is a <strong>metric</strong>?<ul>
<li>A function that measures <strong>quality of model's predictions using validation set</strong> (it is printed at end of each epoch).</li>
<li>Usually the metric is <strong>error rate</strong> (percentage of images classified incorrectly). Other common metric is <strong>accuracy</strong> (<code>1.0-errror_rate</code>).</li>
<li>fastai provides many more metrics</li>
<li>Difference between <strong>metric</strong> and <strong>loss</strong>: <ul>
<li>Loss is a measurement of performance that training system <strong>uses to update weights automatically</strong> (i.e. it is used for SGD)</li>
<li>Metric is for <strong>human consumption</strong>, easy to understand and hews as closely as possible to what you want the model to do</li>
</ul>
</li>
</ul>
</li>
<li>
<strong>Pretrained models</strong> have been trained on some other dataset. You should nearly always use a pretrained model, because you will have a better starting point.</li>
<li>When using a pretrained model, <code>vision_learner</code> will remove last layer, since it is customized to original training task, and replace with one or more layers with randomized weights. This part of the model is known as the <strong>head</strong>.</li>
<li>Using pretrained models allows for training more accurate models, more quickly, with less data, and less time and money. Nevertheless, it is not recognized in academia as much as it should.</li>
<li>Using pretrained model for a task different to what it was originally trained for is known as <strong>transfer learning</strong>.</li>
<li>
<strong>Fine-tuning</strong> is a transfer learning technique where the parameters of a pretrained model are updated by training for additional epochs using a different task to that used for pretraining.</li>
<li>When calling <code>fine-tune</code>, fastai applies following tricks:<ol>
<li>Use one epoch to fit just those parts of the model necessary to get the new random head to work correctly with the dataset</li>
<li>Use number of epochs requested, updating weights of later layers (especially head) faster than earlier layers.</li>
</ol>
</li>
<li>An <strong>epoch</strong> is one complete pass through the dataset. After each epoch, following is printed:<ul>
<li>Epoch number</li>
<li>training and validation set losses (measure of performance)</li>
<li>requested metrics (e.g. error rate)</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="What-Our-Image-Recognizer-Learned">
<a class="anchor" href="#What-Our-Image-Recognizer-Learned" aria-hidden="true"><span class="octicon octicon-link"></span></a>What Our Image Recognizer Learned<a class="anchor-link" href="#What-Our-Image-Recognizer-Learned"> </a>
</h2>
<ul>
<li>Deep learning results are often regarded as a 'black box', i.e. difficult to interpret/explain. However there is a lot of research about how to inspect deep learning models and gain rich insights from them.</li>
<li>Further reading: <em>Visualizing and Understanding Convolutional Networks, Zeiler, Fergus</em>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Image-Recognizer-Can-Tackle-Non-Image-Tasks">
<a class="anchor" href="#Image-Recognizer-Can-Tackle-Non-Image-Tasks" aria-hidden="true"><span class="octicon octicon-link"></span></a>Image Recognizer Can Tackle Non-Image Tasks<a class="anchor-link" href="#Image-Recognizer-Can-Tackle-Non-Image-Tasks"> </a>
</h2>
<ul>
<li>You can represent different things as an image and then use an image recognizer. For instance by converting sound into a spectogram. It is important that when doing this, the components that you would like the deep learning model to recognize, are easily detectable. A good rule of thumb is that if a human eye can detect it, a deep learning model should be able to do so too. </li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Deep-Learning-Is-Not-Just-For-Image-Classification">
<a class="anchor" href="#Deep-Learning-Is-Not-Just-For-Image-Classification" aria-hidden="true"><span class="octicon octicon-link"></span></a>Deep Learning Is Not Just For Image Classification<a class="anchor-link" href="#Deep-Learning-Is-Not-Just-For-Image-Classification"> </a>
</h2>
<ul>
<li>Another application of deep learning is called <em>segmentation</em>. This is about identifying what each pixel in an image belongs to. It is used for instance in autonomous driving.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Example of training a segmentation model using a subset of Camvid dataset shown below. Code is very similar to previous cat/dog classifier.</li>
</ul>
<div class="highlight"><pre><span></span><span class="n">path</span> <span class="o">=</span> <span class="n">untar_data</span><span class="p">(</span><span class="n">URLs</span><span class="o">.</span><span class="n">CAMVID_TINY</span><span class="p">)</span>
<span class="n">dls</span> <span class="o">=</span> <span class="n">SegmentationDataLoaders</span><span class="o">.</span><span class="n">from_label_func</span><span class="p">(</span>
    <span class="n">path</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">fnames</span> <span class="o">=</span> <span class="n">get_image_files</span><span class="p">(</span><span class="n">path</span><span class="o">/</span><span class="s2">"images"</span><span class="p">),</span>
    <span class="n">label_func</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">o</span><span class="p">:</span> <span class="n">path</span><span class="o">/</span><span class="s1">'labels'</span><span class="o">/</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">o</span><span class="o">.</span><span class="n">stem</span><span class="si">}</span><span class="s1">_P</span><span class="si">{</span><span class="n">o</span><span class="o">.</span><span class="n">suffix</span><span class="si">}</span><span class="s1">'</span><span class="p">,</span>
    <span class="n">codes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">loadtxt</span><span class="p">(</span><span class="n">path</span><span class="o">/</span><span class="s1">'codes.txt'</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">str</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">learn</span> <span class="o">=</span> <span class="n">unet_learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">resnet34</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fine_tune</span><span class="p">(</span><span class="mi">8</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">show_results</span><span class="p">(</span><span class="n">max_n</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Example of deep learning NLP model (note to self: could not get it to work. Revisit later to troubleshoot.)</li>
</ul>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">fastai.text.all</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">dls</span> <span class="o">=</span> <span class="n">TextDataLoaders</span><span class="o">.</span><span class="n">from_folder</span><span class="p">(</span><span class="n">untar_data</span><span class="p">(</span><span class="n">URLs</span><span class="o">.</span><span class="n">IMDB</span><span class="p">),</span> <span class="n">valid</span><span class="o">=</span><span class="s1">'test'</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">learn</span> <span class="o">=</span> <span class="n">text_classifier_learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">AWD_LSTM</span><span class="p">,</span> <span class="n">drop_mult</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">accuracy</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fine_tune</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Jupyter">
<a class="anchor" href="#Jupyter" aria-hidden="true"><span class="octicon octicon-link"></span></a>Jupyter<a class="anchor-link" href="#Jupyter"> </a>
</h2>
<ul>
<li>Restart notebook: hit <code>00</code> in command mode to restart notebook (wipes internal state and restarts)</li>
<li>Check documentation fastai: <code>doc([method name])</code>, example: <code>doc(learn.predict)</code>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Datasets:-Food-for-Models">
<a class="anchor" href="#Datasets:-Food-for-Models" aria-hidden="true"><span class="octicon octicon-link"></span></a>Datasets: Food for Models<a class="anchor-link" href="#Datasets:-Food-for-Models"> </a>
</h2>
<ul>
<li>There are curated datasets that serve as <em>academic baselines</em>, i.e. they are used in research to compare model performance</li>
<li>In practice deep learning practitioners use such datasets, but in order to iterate quickly, they use representative subsets of such datasets.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Validation-Sets-and-Test-Sets">
<a class="anchor" href="#Validation-Sets-and-Test-Sets" aria-hidden="true"><span class="octicon octicon-link"></span></a>Validation Sets and Test Sets<a class="anchor-link" href="#Validation-Sets-and-Test-Sets"> </a>
</h2>
<ul>
<li>Goal of a model is to make predictions about data. But if we train model with all our data, we won't be able to tell how well it performs outside of the training data. Therefore we withhold a part of the data and call that part the <strong>validation set</strong>. The rest is called the <strong>training set</strong>.</li>
<li>As we explore different models, there are a lot of variables we play around with. For example: network architecture, learning rates, data augmentation strategies, and so on. These are known as <strong>hyperparameters</strong>. </li>
<li>Hyperparameter tuning can also leads to overfitting. Because of this, we introduce an even more highly reserved dataset, the <strong>test set</strong>. It is only to be used at the very end of our efforts.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Use-Judgment-in-Defining-Test-Sets">
<a class="anchor" href="#Use-Judgment-in-Defining-Test-Sets" aria-hidden="true"><span class="octicon octicon-link"></span></a>Use Judgment in Defining Test Sets<a class="anchor-link" href="#Use-Judgment-in-Defining-Test-Sets"> </a>
</h2>
<ul>
<li>Randomly selecting a test set is not always a good idea. For instance, for a time series, you would usually want to predict what will happen in the future.</li>
<li>In general you don't want your model to be trained based on peculiarities/specifics of the training dataset (e.g. Kaggle fisheries competition, Kaggle distracted driver competition)</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Questionnaire">
<a class="anchor" href="#Questionnaire" aria-hidden="true"><span class="octicon octicon-link"></span></a>Questionnaire<a class="anchor-link" href="#Questionnaire"> </a>
</h2>
<ol>
<li>Do you need these for deep learning?<ul>
<li>Lots of math T / F</li>
<li>Lots of data T / F</li>
<li>Lots of expensive computers T / F</li>
<li>A PhD T / F</li>
</ul>
</li>
<li>Name five areas where deep learning is now the best in the world.<ul>
<li>NLP, computer vision, medicine, biology, image recommendation systems, robotics</li>
</ul>
</li>
<li>What was the name of the first device that was based on the principle of the artificial neuron?<br>
Mark I Perceptron (made by Rosenblatt)</li>
<li>Based on the book of the same name, what are the requirements for parallel distributed processing (PDP)?<ol>
<li>A set of <em>processing units</em>
</li>
<li>A state of <em>activation</em>
</li>
<li>An <em>output function</em> for each unit</li>
<li>A <em>pattern of connectivity</em> among units</li>
<li>A <em>propagation rule</em> for propagating patterns of activities through the network of connectivities</li>
<li>An <em>activation rule</em> for combining inputs impinging on a unit with the current state of that unit to produce an output for the unit</li>
<li>A <em>learning rule</em> whereby patterns of connectivity are modified by experience</li>
<li>An <em>environment</em> within which the system must operate</li>
</ol>
</li>
<li>What were the two theoretical misunderstandings that held back the field of neural networks?<ol>
<li>Simple functions (like XOR) cannot be modelled</li>
<li>?</li>
</ol>
</li>
<li>What is a GPU?<ul>
<li>Graphics Processing Unit, also known as a graphics card, good at performing many tasks at the same time (matrix multiplication)</li>
</ul>
</li>
<li>Open a notebook and execute a cell containing: <code>1+1</code>. What happens?</li>
<li>Follow through each cell of the stripped version of the notebook for this chapter. Before executing each cell, guess what will happen.</li>
<li>Complete the Jupyter Notebook online appendix.</li>
<li>Why is it hard to use a traditional computer program to recognize images in a photo?<ul>
<li>Too much variation in input data (various images), too many rules to program, intractable</li>
</ul>
</li>
<li>What did Samuel mean by "weight assignment"?<ul>
<li>Choice of parameter values</li>
</ul>
</li>
<li>What term do we normally use in deep learning for what Samuel called "weights"?<ul>
<li>parameters</li>
</ul>
</li>
<li>Draw a picture that summarizes Samuel's view of a machine learning model.</li>
<li>Why is it hard to understand why a deep learning model makes a particular prediction?<ul>
<li>?</li>
</ul>
</li>
<li>What is the name of the theorem that shows that a neural network can solve any mathematical problem to any level of accuracy?<ul>
<li>Universal Approximation Theorem</li>
</ul>
</li>
<li>What do you need in order to train a model?<ul>
<li>labeled data</li>
</ul>
</li>
<li>How could a feedback loop impact the rollout of a predictive policing model?<ul>
<li>Based on the data the model could predict certain areas have a higher crime rate, if policing efforts are then focused in those areas, it will lead to more arrests, further reinforcing the model (positive feedback)</li>
</ul>
</li>
<li>Do we always have to use 224×224-pixel images with the cat recognition model?<ul>
<li>No, it is a choice (a hyperparameter)</li>
</ul>
</li>
<li>What is the difference between classification and regression?<ul>
<li>Classification is about predicting categories or classes and regression is about predicting numberic quantities</li>
</ul>
</li>
<li>What is a validation set? What is a test set? Why do we need them?<ul>
<li>Validation set is used to evaluate model accuracy and mitigate overfitting during training</li>
<li>Test set is a more exclusive dataset only to be used at the very end to mitigate overfitting due to hyperparameter tuning</li>
</ul>
</li>
<li>What will fastai do if you don't provide a validation set?<ul>
<li>Take 20% of the data randomly and make it the validation set </li>
</ul>
</li>
<li>Can we always use a random sample for a validation set? Why or why not?<ul>
<li>No, you may not be able to prevent overfitting that way in all cases. For example with time series.</li>
</ul>
</li>
<li>What is overfitting? Provide an example.<ul>
<li>It is when your model learns idiosyncrasies from the training data and therefore does not generalize to data it has not seen before. Example: if you have a computer vision model that tries to determine if an image is that of a cat, but you only have images of the same cat, it will not generalize well to other cats. The model will learn the shape, color, and other specifics of that cat alone.</li>
</ul>
</li>
<li>What is a metric? How does it differ from "loss"?<ul>
<li>A metric is a measure of accuracy of the model. It is for human consumption to determine how well our model is performing. Loss on the other hand is a measure used by the deep learning model to tune the parameters. It is used by SGD.</li>
</ul>
</li>
<li>How can pretrained models help?<ul>
<li>Less data, more accuracy, less time/money</li>
</ul>
</li>
<li>What is the "head" of a model?<ul>
<li>Top layer, predicts what we are interested in</li>
</ul>
</li>
<li>What kinds of features do the early layers of a CNN find? How about the later layers?<ul>
<li>Early: lines, gradients, later: patterns, shapes</li>
</ul>
</li>
<li>Are image models only useful for photos?<ul>
<li>No, you can represent different data as images and use an image model (e.g. spectogram for audio)</li>
</ul>
</li>
<li>What is an "architecture"?<ul>
<li>The deep learning network</li>
</ul>
</li>
<li>What is segmentation?<ul>
<li>Identifying what each pixel of an image is a pixel of </li>
</ul>
</li>
<li>What is <code>y_range</code> used for? When do we need it?<ul>
<li>Range of our target, we need it when predicting a continuous number (rather than a category)</li>
</ul>
</li>
<li>What are "hyperparameters"?<ul>
<li>A parameter that is used to control the learning process (e.g. model architecture, learning rate, batch size, etc.)</li>
</ul>
</li>
<li>What's the best way to avoid failures when using AI in an organization?<ul>
<li>Test set that machine learning engineers do not get to use</li>
</ul>
</li>
</ol>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="kemal-nl/personal-blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/personal-blog/fast-ai-book/2022/08/11/fastai-book-chapter-1.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/personal-blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/personal-blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/personal-blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Personal blog with notes for fast.ai</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"></ul>
</div>

  </div>

</footer>
</body>

</html>
